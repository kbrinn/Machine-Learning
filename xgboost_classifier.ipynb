{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_tree\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "data_frame=pd.read_csv('D:/xgboost_cancer_classifier/data.csv',sep=',',index_col=False,header=0)\n",
    "data_frame=data_frame.replace({'diagnosis':{'M':1,'B':0}})\n",
    "data_frame[\"diagnosis\"]=data_frame['diagnosis'].astype('int32')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "features_DF=pd.DataFrame(data_frame,columns=['radius_mean',\n",
    "                                             'texture_mean','perimeter_mean',\n",
    "                                             'area_mean','smoothness_mean',\n",
    "                                             'compactness_mean','concavity_mean',\n",
    "                                             'concave points_mean','symmetry_mean',\n",
    "                                             'fractal_dimension_mean','radius_se',\n",
    "                                             'texture_se','perimeter_se','area_se',\n",
    "                                             'smoothness_se','compactness_se',\n",
    "                                             'concavity_se','concave points_se',\n",
    "                                             'symmetry_se','fractal_dimension_se',\n",
    "                                             'radius_worst','texture_worst',\n",
    "                                             'perimeter_worst','area_worst',\n",
    "                                             'smoothness_worst','compactness_worst',\n",
    "                                             'concavity_worst','concave points_worst',\n",
    "                                             'symmetry_worst','fractal_dimension_worst'])\n",
    "\n",
    "label_DF=pd.DataFrame(data_frame,columns=['diagnosis'])\n",
    "\n",
    "features_DF=features_DF.to_numpy()\n",
    "label_DF=label_DF.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "(X_train,X_test,Y_train,Y_test) = train_test_split(features_DF,label_DF, test_size=.10,random_state=7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the model with default hyper parameters:\n",
    "\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
    "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy: 98.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\xgboost_cancer_classifier\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\xgboost_cancer_classifier\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Initialize an XGBClassifier with the tuned parameters and fit the training data\n",
    "#predicting for training set\n",
    "\n",
    "model=XGBClassifier()\n",
    "model.fit(X_train,Y_train)\n",
    "predictions=model.predict(X_test)\n",
    "accuracy=accuracy_score(Y_test,predictions)\n",
    "print(model)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "now with bayesian optimization methods to find best model hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "d_matrix = xgb.DMatrix(features_DF, label_DF)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "According to documentation, there is a tradeoff between number of learners-\n",
    "and learning rate. Large numbers of trees + small learning rate does not-\n",
    "provide optimal results. Learning rate between 0.1-0.125 and between 100 - 500-\n",
    "number of trees.\n",
    "\n",
    "When finding optimal hyperparameters using Bayesian optimization, is important-\n",
    "to know the boundaries of the hyperparameters to enclose our function to optimize.\n",
    "\n",
    "\n",
    "Bibliography on hyperparameter tuning:\n",
    "\n",
    "https://www.youtube.com/watch?v=wPqtzj5VZus\n",
    "\n",
    "www.saedsayad.com/docs/gbm2.pdf\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def xgboost_optimized(max_depth,gamma,learning_rate,n_estimators,subsample,colsample_bytree):\n",
    "\n",
    "    params={'max_depth':int(max_depth),'gamma':gamma,\n",
    "            'n_estimators':int(n_estimators),\n",
    "            'learning_rate':learning_rate,\n",
    "            'subsample':subsample,'colsample_bytree':colsample_bytree,\n",
    "            'eval_metric':'rmse'}\n",
    "\n",
    "    cv_result=xgb.cv(params,d_matrix,num_boost_round=700,nfold=5)\n",
    "\n",
    "    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "xgb_bo = BayesianOptimization(xgboost_optimized, {'max_depth': (3,8),\n",
    "                                             'gamma': (0,1),\n",
    "                                             'learning_rate':(0.095,0.125),\n",
    "                                             'n_estimators':(100,500),\n",
    "                                             'subsample':(0.4,0.6),\n",
    "                                             'colsample_bytree':(0.4,0.6),\n",
    "                                            })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001B[0m 1       \u001B[0m | \u001B[0m-0.1763  \u001B[0m | \u001B[0m 0.5106  \u001B[0m | \u001B[0m 0.2006  \u001B[0m | \u001B[0m 0.0967  \u001B[0m | \u001B[0m 4.073   \u001B[0m | \u001B[0m 362.1   \u001B[0m | \u001B[0m 0.4019  \u001B[0m |\n",
      "| \u001B[0m 2       \u001B[0m | \u001B[0m-0.1915  \u001B[0m | \u001B[0m 0.403   \u001B[0m | \u001B[0m 0.8207  \u001B[0m | \u001B[0m 0.1241  \u001B[0m | \u001B[0m 5.204   \u001B[0m | \u001B[0m 203.9   \u001B[0m | \u001B[0m 0.5519  \u001B[0m |\n",
      "| \u001B[0m 3       \u001B[0m | \u001B[0m-0.1839  \u001B[0m | \u001B[0m 0.4349  \u001B[0m | \u001B[0m 0.4258  \u001B[0m | \u001B[0m 0.1071  \u001B[0m | \u001B[0m 3.489   \u001B[0m | \u001B[0m 428.5   \u001B[0m | \u001B[0m 0.5342  \u001B[0m |\n",
      "| \u001B[95m 4       \u001B[0m | \u001B[95m-0.1713  \u001B[0m | \u001B[95m 0.4623  \u001B[0m | \u001B[95m 0.1426  \u001B[0m | \u001B[95m 0.1196  \u001B[0m | \u001B[95m 7.567   \u001B[0m | \u001B[95m 410.6   \u001B[0m | \u001B[95m 0.548   \u001B[0m |\n",
      "| \u001B[0m 5       \u001B[0m | \u001B[0m-0.1905  \u001B[0m | \u001B[0m 0.5561  \u001B[0m | \u001B[0m 0.7953  \u001B[0m | \u001B[0m 0.1162  \u001B[0m | \u001B[0m 7.782   \u001B[0m | \u001B[0m 442.5   \u001B[0m | \u001B[0m 0.415   \u001B[0m |\n",
      "| \u001B[0m 6       \u001B[0m | \u001B[0m-0.1751  \u001B[0m | \u001B[0m 0.5188  \u001B[0m | \u001B[0m 0.4106  \u001B[0m | \u001B[0m 0.1231  \u001B[0m | \u001B[0m 7.52    \u001B[0m | \u001B[0m 371.9   \u001B[0m | \u001B[0m 0.431   \u001B[0m |\n",
      "| \u001B[0m 7       \u001B[0m | \u001B[0m-0.1735  \u001B[0m | \u001B[0m 0.4069  \u001B[0m | \u001B[0m 0.122   \u001B[0m | \u001B[0m 0.119   \u001B[0m | \u001B[0m 6.135   \u001B[0m | \u001B[0m 146.0   \u001B[0m | \u001B[0m 0.4946  \u001B[0m |\n",
      "| \u001B[0m 8       \u001B[0m | \u001B[0m-0.1829  \u001B[0m | \u001B[0m 0.4252  \u001B[0m | \u001B[0m 0.5853  \u001B[0m | \u001B[0m 0.1221  \u001B[0m | \u001B[0m 7.02    \u001B[0m | \u001B[0m 102.1   \u001B[0m | \u001B[0m 0.4566  \u001B[0m |\n",
      "| \u001B[0m 9       \u001B[0m | \u001B[0m-0.1765  \u001B[0m | \u001B[0m 0.4643  \u001B[0m | \u001B[0m 0.08763 \u001B[0m | \u001B[0m 0.1087  \u001B[0m | \u001B[0m 7.28    \u001B[0m | \u001B[0m 411.3   \u001B[0m | \u001B[0m 0.5715  \u001B[0m |\n",
      "| \u001B[0m 10      \u001B[0m | \u001B[0m-0.1854  \u001B[0m | \u001B[0m 0.5175  \u001B[0m | \u001B[0m 0.7215  \u001B[0m | \u001B[0m 0.101   \u001B[0m | \u001B[0m 7.305   \u001B[0m | \u001B[0m 409.8   \u001B[0m | \u001B[0m 0.5387  \u001B[0m |\n",
      "| \u001B[0m 11      \u001B[0m | \u001B[0m-0.1733  \u001B[0m | \u001B[0m 0.4617  \u001B[0m | \u001B[0m 0.05707 \u001B[0m | \u001B[0m 0.1221  \u001B[0m | \u001B[0m 6.075   \u001B[0m | \u001B[0m 146.0   \u001B[0m | \u001B[0m 0.5557  \u001B[0m |\n",
      "| \u001B[95m 12      \u001B[0m | \u001B[95m-0.1688  \u001B[0m | \u001B[95m 0.5101  \u001B[0m | \u001B[95m 0.04068 \u001B[0m | \u001B[95m 0.1196  \u001B[0m | \u001B[95m 5.626   \u001B[0m | \u001B[95m 146.5   \u001B[0m | \u001B[95m 0.5679  \u001B[0m |\n",
      "| \u001B[0m 13      \u001B[0m | \u001B[0m-0.1858  \u001B[0m | \u001B[0m 0.5614  \u001B[0m | \u001B[0m 0.6183  \u001B[0m | \u001B[0m 0.09754 \u001B[0m | \u001B[0m 5.605   \u001B[0m | \u001B[0m 146.7   \u001B[0m | \u001B[0m 0.4079  \u001B[0m |\n",
      "| \u001B[0m 14      \u001B[0m | \u001B[0m-0.193   \u001B[0m | \u001B[0m 0.5544  \u001B[0m | \u001B[0m 0.8184  \u001B[0m | \u001B[0m 0.0979  \u001B[0m | \u001B[0m 7.825   \u001B[0m | \u001B[0m 372.5   \u001B[0m | \u001B[0m 0.5349  \u001B[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "xgb.set_config(verbosity=0)\n",
    "optimal_network=xgb_bo.maximize(n_iter=6, init_points=8, acq='ei')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5100677145591068, 'gamma': 0.040679526310111735, 'learning_rate': 0.119577660717184, 'max_depth': 5.62551361134971, 'n_estimators': 146.5094981490878, 'subsample': 0.5678950830021507}\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.5100677145591068,\n",
      "              gamma=0.040679526310111735, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.119577660717184,\n",
      "              max_delta_step=0, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=146, n_jobs=12,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=0.5678950830021507,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy: 98.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\xgboost_cancer_classifier\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\xgboost_cancer_classifier\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Extracting the best parameters\n",
    "params = xgb_bo.max['params']\n",
    "print(params)\n",
    "\n",
    "#Converting the max_depth and n_estimator values from float to int\n",
    "params['max_depth']= int(params['max_depth'])\n",
    "params['n_estimators']= int(params['n_estimators'])\n",
    "\n",
    "#Initialize an XGBClassifier with the tuned parameters and fit the training data\n",
    "\n",
    "model_2=XGBClassifier(**params)\n",
    "model_2.fit(X_train,Y_train)\n",
    "\n",
    "#predicting for training set\n",
    "predictions=model.predict(X_test)\n",
    "accuracy_2=accuracy_score(Y_test,predictions)\n",
    "print(model_2)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_2*100))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataset by:\n",
    " https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}